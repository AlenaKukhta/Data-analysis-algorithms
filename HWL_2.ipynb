{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание к Уроку 1. Алгоритм линейной регрессии. Градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Сгенерировать датасет при помощи sklearn.datasets.make_regression и обучить линейную модель при помощи градиентного и стохастического градиентного спуска. Нанести среднеквадратичную ошибку для обоих методов на один график, сделать выводы о разнице скорости сходимости каждого из методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция, определяющая среднеквадратичную ошибку\n",
    "def mserror(X, w, y_pred):\n",
    "    y = X.dot(w)\n",
    "    return (sum((y - y_pred)**2)) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target, coef = datasets.make_regression(n_samples=1000, n_features = 2, n_informative = 2, n_targets = 1, \n",
    "                                              noise = 5, coef = True, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37879447, -0.61837549],\n",
       "       [-0.65293115, -1.06706712],\n",
       "       [-1.06581629, -0.34682333],\n",
       "       ...,\n",
       "       [ 1.19451016,  1.00147133],\n",
       "       [ 0.1256231 ,  0.35261274],\n",
       "       [-0.05674652,  0.41214611]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В результате выполнения градиентного спуска функционал ошибки = 26.4259\n",
      "Количество выполненных итераций = 986\n"
     ]
    }
   ],
   "source": [
    "X = data.copy()\n",
    "Y = target.copy()\n",
    "\n",
    "# начальный вектор весов\n",
    "w = np.zeros(2)\n",
    "\n",
    "# список векторов весов после каждой итерации\n",
    "w_list = [w.copy()]\n",
    "\n",
    "# список значений ошибок после каждой итерации\n",
    "errors_gs = []\n",
    "\n",
    "# шаг градиентного спуска\n",
    "eta = 0.01\n",
    "\n",
    "# максимальное число итераций\n",
    "max_iter = 1e4\n",
    "\n",
    "# критерий сходимости (разница весов, при которой алгоритм останавливается)\n",
    "min_weight_dist = 1e-8\n",
    "\n",
    "# начальная разница весов большим числом\n",
    "weight_dist = np.inf\n",
    "\n",
    "# счетчик итераций\n",
    "iter_num = 0\n",
    "\n",
    "# ход градиентного спуска\n",
    "while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "    new_w = w - 2 * eta * np.dot(X.T, (np.dot(X, w) - Y)) / Y.shape[0]\n",
    "    weight_dist = np.linalg.norm(new_w - w, ord=2)\n",
    "    \n",
    "    w_list.append(new_w.copy())\n",
    "    errors_gs.append(mserror(X, new_w, Y))\n",
    "    \n",
    "    iter_num += 1\n",
    "    w = new_w\n",
    "    \n",
    "w_list = np.array(w_list)\n",
    "\n",
    "print(f'В результате выполнения градиентного спуска функционал ошибки = {round(errors_gs[-1], 4)}')\n",
    "print(f'Количество выполненных итераций = {iter_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В результате выполнения стохастического градиентного спуска функционал ошибки = 457.0203\n",
      "Количество выполненных итераций = 75746\n"
     ]
    }
   ],
   "source": [
    "data = data.copy()\n",
    "target = target.copy()\n",
    "# начальный вектор весов\n",
    "w = np.zeros(2)\n",
    "\n",
    "# список векторов весов после каждой итерации\n",
    "w_list = [w.copy()]\n",
    "\n",
    "# список значений ошибок после каждой итерации\n",
    "errors_sgs = []\n",
    "\n",
    "# шаг градиентного спуска\n",
    "eta = 0.01\n",
    "\n",
    "# максимальное число итераций\n",
    "max_iter = 1e5\n",
    "\n",
    "# критерий сходимости (разница весов, при которой алгоритм останавливается)\n",
    "min_weight_dist = 1e-8\n",
    "\n",
    "# начальная разница весов большим числом\n",
    "weight_dist = np.inf\n",
    "\n",
    "# счетчик итераций\n",
    "iter_num = 0\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# ход градиентного спуска\n",
    "while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "    \n",
    "    # случайный индекс объекта выборки\n",
    "    train_ind = np.random.randint(data.shape[0])\n",
    "    \n",
    "    new_w = w - 2 * eta * np.dot(data[train_ind].T, (np.dot(data[train_ind], w) - target[train_ind])) / target.shape[0]\n",
    "\n",
    "    weight_dist = np.linalg.norm(new_w - w, ord=2)\n",
    "    \n",
    "    w_list.append(new_w.copy())\n",
    "    errors_sgs.append(mserror(data, new_w, target))\n",
    "    \n",
    "    iter_num += 1\n",
    "    w = new_w\n",
    "    \n",
    "w_list = np.array(w_list)\n",
    "\n",
    "print(f'В результате выполнения стохастического градиентного спуска функционал ошибки = {round(errors_sgs[-1], 4)}')\n",
    "print(f'Количество выполненных итераций = {iter_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt+0lEQVR4nO3de7yVc97/8ddnV1KUSgdpR8VGaYj2JIfBIOVYDCPD1MzwyyGMMYZi7nG4mbsZ5nDn0JRhFIluwxSjSMYYNLJFOkkllKIYh4R0+Pz++H63Vqu1W7Xb177W3vv9fDyux7qu73VYn6302df3aO6OiIjIlhSlHYCIiBQ+JQsREclLyUJERPJSshARkbyULEREJC8lCxERyUvJQkRE8lKyEKkCZva2mX1tZi2zyl8zMzezDmZWbGZ/NbMPzexTM5tlZj+K13WI132etZ2Vyg8kkqV+2gGI1CKLgbOB2wDM7FtAo4zz9wEzgT2BNcC3gN2yntHM3dclH6rIttGbhUjVuQ8YkHE8EBiTcfxt4F53X+3u69z9VXefVK0RilSSkoVI1fk30NTMOptZPeAs4P6s83eYWX8z2yOVCEUqSclCpGqVv130At4A3ss4dybwL+C/gMWxPePbWfd/aGafZGydqyVqkTzUZiFSte4DngM6smkVFO7+MTAEGBIbwm8F/mZmxRmXtVSbhRQivVmIVCF3f4fQ0H0i8MgWrvuQkCx2B1pUT3QiladkIVL1zgOOcffVmYVm9hsz62pm9c2sCXARsNDdP0olSpFtoGQhUsXcfZG7l+U41Rh4FPgEeIvQhfbUrGs+yRpncUWy0YpsHdPiRyIiko/eLEREJC8lCxERyUvJQkRE8lKyEBGRvGrtoLyWLVt6hw4d0g5DRKRGeeWVVz5091bZ5bU2WXTo0IGysly9F0VEpCJm9k6uclVDiYhIXkoWIiKSl5KFiIjkpWQhIiJ5KVmIiEheShYiIpKXkoWIiOSlZJHJHe65ByZOTDsSEZGCUmsH5VXKunVwxx2wfDkcdxw0bpx2RCIiBUFvFpkaNIA//CEki9tvTzsaEZGCkWiyMLOfmdkcM5ttZuPMbEcza2FmU8xsQfxsnnH9UDNbaGbzzax3Rnl3M5sVzw03M0ss6COPhBNOgGHD4JNPEvsaEZGaJLFkYWbtgMuAUnfvCtQD+gNDgKnuXgJMjceYWZd4fn+gD3CnmdWLjxsBDAJK4tYnqbgBuPlm+PhjuPXWRL9GRKSmSLoaqj7QyMzqE9YfXgb0BUbH86OBfnG/L/Cgu69x98XAQqCHmbUFmrr7NA9rwI7JuCcZBx0E/fuHKqn330/0q0REaoLEkoW7vwfcCrwLLAc+dfengDbuvjxesxxoHW9pByzJeMTSWNYu7meXb8bMBplZmZmVrVy5cvt+gBtvhDVrwluGiEgdl2Q1VHPC20JHYHdgJzM7d0u35CjzLZRvXug+yt1L3b20VavNpmPfKl+v/5q169dCSQmcdx6MHAlLluS/UUSkFkuyGuo4YLG7r3T3tcAjwGHAB7Fqifi5Il6/FGifcX8xodpqadzPLk/EQSMP4geP/CAcDB0KGzbo7UJE6rwkk8W7QE8zaxx7Lx0LzAMmAgPjNQOBCXF/ItDfzBqaWUdCQ/b0WFW1ysx6xucMyLgnWR06wIUXwl13wZtvVstXiogUoiTbLF4CHgZmALPid40ChgG9zGwB0Cse4+5zgPHAXGAyMNjd18fHXQT8mdDovQiYlFTcm/nlL2GHHeC3v622rxQRKTSJjuB29+uA67KK1xDeMnJdfzOwWZ2Pu5cBXas8wAqETlfRbrvB+efDiBEwZAjsvXd1hSEiUjA0gjuL5WpPv+aa8HZxww3VH5CISAFQstgabdvCJZfA2LEwY0ba0YiIVDslixw8V8/ca66BVq3gqquqPyARkZQpWWSpcNqpZs3gyith6lSYPLlaYxIRSZuSxba47DLYd1+4+GL44ou0oxERqTZKFjls0hsqU8OGYUT34sWaZFBE6hQliyw5e0NlOuoo+P734aab4O23qyUmEZG0KVlUxq23hoWSLrww7UhERKqFkkUOOXtDZWrfHv77v+HJJ2HKlOoJSkQkRUoWWbZ6Eb6LL4a99oJLL4W1a5MNSkQkZUoWlbXjjmFxpPnzYfTo/NeLiNRgShY5VNgbKtvJJ0NpaaiS+uqrZIMSEUmRkkWWvL2hNrnYwmy0774Lw4cnF5SISMqULLbXd78Lp5wC118PCxemHY2ISCKULKrCiBFhVtoBA2Brq7BERGqQJNfg3tfMXsvYPjOzy82shZlNMbMF8bN5xj1DzWyhmc03s94Z5d3NbFY8N9y2ustS5eTtOputXbsw9mLaNJhQPYv4iYhUpyRXypvv7t3cvRvQHfgCeBQYAkx19xJgajzGzLoA/YH9gT7AnWZWLz5uBDCIsNRqSTyfiErnoQEDoGtXGDwYPv64aoMSEUlZdVVDHQsscvd3gL5AeV/T0UC/uN8XeNDd17j7YsISqj3MrC3Q1N2neeimNCbjnsKxww7wl7/AihVhRT0RkVqkupJFf2Bc3G/j7ssB4mfrWN4OWJJxz9JY1i7uZ5dvxswGmVmZmZWtXLmy0sFuddfZbKWlMGhQSBrz5lX6+0VECk3iycLMdgBOBf4v36U5ynwL5ZsXuo9y91J3L23VqtW2BfpNENvZHPKrX8HOO4ekocZuEaklquPN4gRghrt/EI8/iFVLxM8VsXwp0D7jvmJgWSwvzlFemNq0CWMvnn8eHngg7WhERKpEdSSLs9lYBQUwERgY9wcCEzLK+5tZQzPrSGjInh6rqlaZWc/YC2pAxj2J2ObeUNl+9KNQJTV4cGjDEBGp4RJNFmbWGOgFPJJRPAzoZWYL4rlhAO4+BxgPzAUmA4PdfX285yLgz4RG70XApARj3v6H1K8PY8bA6tVhokFVR4lIDVc/yYe7+xfArlllHxF6R+W6/mbg5hzlZUDXJGJMTOfOcMMNcO21YYT3ueemHZGISKVpBHcOle4Nle3qq+Hww8N05osWVc0zRURSoGSRZbt7Q2WqVw/uuw/WrYMrrqi654qIVDMli6R17Ai//CVMnAhPP512NCIilaJkkcN294bKdsUV0KlTqI7SuhciUgMpWWRJZI7CHXcMM9MuWBAavEVEahgli+py/PFwwQXw+9/DqFFpRyMisk2ULKrT7bdDr16hWmrJkvzXi4gUCCWLHKqs62y2+vVh5MjQO+oXv0jmO0REEqBkkaVKu87m0rFjeLMYPx5mz072u0REqoiSRRquuAKaNQsLJq1bl3Y0IiJ5KVnkUOVdZ7O1bBmqo159Fe68M9nvEhGpAkoWWRJe3nujM84IPaSuuQbmzKme7xQRqSQli7SYwV13QePGWihJRAqekkUOifWGyrbHHnDjjfDii/DYY9XznSIilaBkkSXx3lDZfvIT6NIlLJT0wQf5rxcRSUHSix81M7OHzewNM5tnZoeaWQszm2JmC+Jn84zrh5rZQjObb2a9M8q7m9mseG64VVvDQjXYYQe4996wot4PfgAbNqQdkYjIZpJ+s/hfYLK77wccCMwDhgBT3b0EmBqPMbMuQH9gf6APcKeZ1YvPGQEMIiy1WhLPJybx3lDZvv1t+MMf4Jln4Lbbqve7RUS2QmLJwsyaAkcCdwO4+9fu/gnQFxgdLxsN9Iv7fYEH3X2Nuy8mLKHaw8zaAk3dfZqHxoQxGfckEXdSj96yiy4KK+r94hfwyivpxCAiUoEk3yw6ASuBv5jZq2b2ZzPbCWjj7ssB4mfreH07IHPCpKWxrF3czy7fjJkNMrMyMytbuXJl1f40STODe+6BNm2gXz9YtiztiEREvpFksqgPHAyMcPeDgNXEKqcK5PqV3rdQvnmh+yh3L3X30latWm1rvOlr2RIefxw++QROOw2+/DLtiEREgGSTxVJgqbu/FI8fJiSPD2LVEvFzRcb17TPuLwaWxfLiHOWJqbaus7kceCCMHg3Tp8OFF2r8hYgUhMSShbu/Dywxs31j0bHAXGAiMDCWDQQmxP2JQH8za2hmHQkN2dNjVdUqM+sZe0ENyLinylV719lcTj8d/uu/YMyYMHBPRCRl9RN+/qXAWDPbAXgL+DEhQY03s/OAd4EzAdx9jpmNJySUdcBgd18fn3MRcC/QCJgUt9rtuuvC28Wll0K3btCjR9oRiUgdlmiycPfXgNIcp46t4PqbgZtzlJcBXas0uC2o9q6zudSrB2PHQmkpnHQSPPccdO6cdlQiUkdpBHeWghrvt+uuMGlSGKh37rmwZk3aEYlIHaVkUej22w/uvhtmzIArr0w7GhGpo5Qscki1N1Qu/frBz34W1vC+5560oxGROkjJIktB9IbK5Te/geOOg4svhjfeSDsaEaljlCxqigYN4L77YOed4fvfh1Wr0o5IROoQJYscCqI3VC677QbjxsHcuaFq6uuv045IROoIJYssBdUbKpdevUK7xTPPwGWXaYS3iFSLpAflSRIGDIDZs+GWW+Cgg+CCC9KOSERqOb1Z5FBwvaFyGTYMeveGSy6BJ59MOxoRqeWULLIUbG+obEVF8NBDYRzGGWfA/PlpRyQitZiSRU22yy5hhHfDhnDWWfDVV2lHJCK1lJJFTVdcHKY0nzkTfvxjWL8+/z0iIttIySKHgu06W5GTTgqD9h58EM4/Xz2kRKTKqTdUloLvOluRq66C1avhxhthzz3h+uvTjkhEahEli9rk+uth0SK44QbYYw/4yU/SjkhEaolEq6HM7G0zm2Vmr5lZWSxrYWZTzGxB/Gyecf1QM1toZvPNrHdGeff4nIVmNtwS/vW/RnSdzcUM/vKXMHDvwgth6tS0IxKRWqI62iy+6+7d3L18EaQhwFR3LwGmxmPMrAvQH9gf6APcaWb14j0jgEGEpVZL4vlE1JiusxVp0CC0Xey9N5x5JrzzTtoRiUgtkEYDd19gdNwfDfTLKH/Q3de4+2JgIdDDzNoCTd19modf+cdk3CO5tGgBjz0Wekb17g2ffJJ2RCJSwyWdLBx4ysxeMbNBsayNuy8HiJ+tY3k7YEnGvUtjWbu4n12+GTMbZGZlZla2cuXK7Qi6hlZDZdprL5g4MbRhnHyyxmCIyHZJOlkc7u4HAycAg83syC1cm6v+x7dQvnmh+yh3L3X30latWm17tNTg3lC5HHUU3H8/vPAC9O+vWWpFpNISTRbuvix+rgAeBXoAH8SqJeLninj5UqB9xu3FwLJYXpyjXLbGWWfBbbfBhAmhd9SGDWlHJCI1UGLJwsx2MrMm5fvA8cBsYCIwMF42EJgQ9ycC/c2soZl1JDRkT49VVavMrGfsBTUg455E1NjeUBW55BK46SYYOzZ8iohsoyTHWbQBHo3VOvWBB9x9spm9DIw3s/OAd4EzAdx9jpmNB+YC64DB7l4+d8VFwL1AI2BS3BJR43tDVeSaa8Jkg9dfD6WlcOKJaUckIjVIYsnC3d8CDsxR/hFwbAX33AzcnKO8DOha1THWKWYwcmSYQ+rMM2HyZPjOd9KOSkRqCM0NlUOt6A2VS6NGYe2L4mL43vfgvffSjkhEaggliyy1qjdULrvtBo8+Cl98EaqiPv447YhEpAZQsqiLunQJCeONN8Kgve0YkyIidYOSRV3Vqxf83/+Ftbz79IFVq9KOSEQKmJJFDrWu62xFTj0VHn4YXn8d+vXTKG8RqZCSRZZa23W2IieeCPfeC888A6edFtbEEBHJomQhcM45cNdd8NRT4W1j7dq0IxKRAqNkkUOt7Tq7JeefH8ZhPPNMmHhQbxgikmGLycLMzs3YPzzr3CVJBZWmWt91dkvOPx/+9Cd4+mk45ZTQvVZEhPxvFldk7N+WdU5rdtZGF1wAo0fDs8+Gkd6aqVZEyJ8srIL9XMe1Rp3pDVWRc8+FESPgiSdCe8aaNWlHJCIpyzc3lFewn+u4VqhzvaEqcsEFod3i5z+HFSvg8cehSZO0oxKRlORLFvuZ2euEt4i94j7xuFOikUn6rrgC2rYNbxp9+sCkSdC0adpRiUgK8iWLztUSRYGpk72hKnL22dCgQVhp76STYMoU2HHHtKMSkWq2xTYLd38ncwM+Bw4GWsbjWqdO94aqyBlnhOVZn38+NHqrl5RInZOv6+zjZtY17rclrHT3E+A+M7s8+fCkYPTvHxq9//53OP54zSUlUsfk6w3V0d1nx/0fA1Pc/RTgELay66yZ1TOzV83s8XjcwsymmNmC+Nk849qhZrbQzOabWe+M8u5mNiueG24J//pf53tDVeTCC+Ghh+Df/w4TEX7+edoRiUg1yZcsMud9OBZ4AsDdVwEbtvI7fgrMyzgeAkx19xJgajzGzLoA/YH9gT7AnWZWL94zAhhEWJe7JJ5PhHpD5XHmmTB+PEyfHvbVrVakTsiXLJaY2aVmdhqhrWIygJk1Ahrke7iZFQMnAX/OKO4LjI77o4F+GeUPuvsad18MLAR6xOqvpu4+zcOv/GMy7pE0nH463HlnWJr1jDNg/fr894hIjZYvWZxH+E3/R8BZ7v5JLO8J/GUrnv9H4Co2fQtp4+7LAeJn61jeDliScd3SWNYu7meXb8bMBplZmZmVrdSCPsm68EK4/fYw/uKcczTSW6SW22LXWXdfAVyYo/wfwD+2dK+ZnQyscPdXzOzorYglV/2Pb6F880L3UcAogNLS0ko3PKjr7FYaPDgM3Lv6avjySxg3Dho3TjsqEUnAFpOFmU3c0nl3P3ULpw8HTjWzE4EdgaZmdj/wgZm1dfflsYppRbx+KdA+4/5iYFksL85Rngh1nd1GV10FO+0El1wCRxwBjz0G7XK++IlIDZavGupQwj/O/wJuBX6XtVXI3Ye6e7G7dyA0XD/j7ucCE4GB8bKBwIS4PxHob2YNzawjoSF7eqyqWmVmPWMvqAEZ90ghGDw4VEctWAClpWFtbxGpVfIli92Aa4CuwP8CvYAP3f2f7v7PSn7nMKCXmS2IzxsG4O5zgPHAXEJD+mB3L285vYjQSL4QWARMquR3bxV1na2Ek06CadNgwwbo3RvefDPtiESkCuUbwb3e3Se7+0BCo/ZC4Fkzu3RbvsTdn3X3k+P+R+5+rLuXxM//ZFx3s7vv5e77uvukjPIyd+8az13iCf5rrq6z26Fr1zB/1OrV0LMn/LOyv0+ISKHJu1JerBY6HbgfGAwMBx5JOjCpoQ4+OAzaa90ajjsOxoxJOyIRqQL5GrhHE6qgJgE3ZIzmrtXUG2o77b13SBjf+x4MHAjz5sFNN0G9evnvFZGClO/N4ofAPoRR2C+a2WdxW2VmnyUfXvVTb6gq0qxZGLR3wQUwbBj066cJCEVqsHzjLPJWU4lUqEGDsKb3AQeErrWHHgqPPgqdtBSKSE2jZJCDekNVsYsvDrPVLlkChx0GM2akHZGIbCMliyzqDZWQE06AF16Ahg3hqKPCZIRKyiI1hpKFVJ/OncNYjP33h7POCo3fq1enHZWIbAUlixzUGypBu+8O//oX/OpXYfW9Ll3CG4eIFDQliyzqDVUNGjSAG24Ig/YaNICjj4ZbblG1lEgBU7KQ9HznO/Dyy3DiiWFCwrPO0nKtIgVKyULS1bx56E7761/Dww+HaULeeivtqEQki5JFDuo6W82KimDoUHj6aXjvvTBlyN//nnZUIpJBySKLus6m6Jhj4NVXYa+9oG/fMPJbS7aKFAQlCyksHTvCs8+Gdb6HDg2N3+++m3ZUInWekkUO6jqbsiZN4KGHwoy1M2dC9+7wxBNpRyVSpyWWLMxsRzObbmYzzWyOmd0Qy1uY2RQzWxA/m2fcM9TMFprZfDPrnVHe3cxmxXPDLcH+reo6WyDM4Ic/hJdeCsu0nnwyXH89rF2bdmQidVKSbxZrgGPc/UCgG9DHzHoCQ4Cp7l4CTI3HmFkXwvKr+wN9gDvNrHxO6xHAIMJSqyXxvNQFnTvDiy/COeeEsRl9+sCHH6YdlUidk1iy8ODzeNggbg70BUbH8tFAv7jfF3jQ3de4+2LCqnw9zKwt0NTdp8UV8sZk3JNU7Ek+XrZV48Zw331wzz3w/PNhRb5//SvtqETqlETbLMysnpm9BqwAprj7S0Abd18OED9bx8vbAUsybl8ay9rF/ezyXN83yMzKzKxs5cqVlYtZvaEK149/HAbxNW0aek4NG6ZR3yLVJNFkEdfw7gYUE94Sum7h8lz/SvsWynN93yh3L3X30latWm1zvFIDHHAATJ8Op50WekuddJJ6S4lUg2rpDeXunwDPEtoaPohVS8TPFfGypUD7jNuKgWWxvDhHeXLxqjdUYWvWLPSWGj48zC/VpQvcfbfeMkQSlGRvqFZm1izuNwKOA94AJgID42UDgQlxfyLQ38wamllHQkP29FhVtcrMesZeUAMy7kki7qQeLVXJDC69FObMgdJSOP98OPVUWLo0/70iss2SfLNoC/zDzF4HXia0WTwODAN6mdkCoFc8xt3nAOOBucBkYLC7lw/fvQj4M6HRexEwKcG4pSbp0CFME/K738HUqaHxe/Ro2LAh7chEahWrrT1/SktLvaysbJvvO+2h01j0n0W8ftHrCUQliVq4MCyo9OKLcOyxcO+9UFyc9zYR2cjMXnH30uxyjeDOot5QNdjee4cutSNHhgWVOneGO+7QW4ZIFVCykNqlqAgGDQptGYcdBpdcAkccAXPnph2ZSI2mZCG1U6dOMHlymF9q/nzo1i2MAF+zJu3IRGokJYsc1HW2liifX2rePDjzzDC31EEHac1vkUpQssiirrO1UOvWMHZsmLl29epQLXXOObAs0eE6IrWKkoXUHSecENoyrr0W/vpX2HdfuOUW+PrrtCMTKXhKFjnU1u7EAuy8M9x0U2jwPuYYuOoqOPBAePLJtCMTKWhKFlnUdbaO6NQJJkyAxx8PbxZ9+sBRR4VlXUVkM0oWUreddFJ4yxg+PHx27x663q5Ykf9ekTpEySIH9YaqYxo2DPNMLVgAl18e1s3o2BF+8QslDZFIySKLekPVYc2awe9/HxrBTz897HfsGNo1Pv447ehEUqVkIZJt333Dynxz5oR1M269NUxYeOON8PnneW8XqY2ULHJQbygBYL/94P77YebMMDHhddfBXnvBbbdpJLjUOUoWWdQbSjbzrW/BI4/AtGlhcsLLLgvVU7fcAh99lHZ0ItVCyUJka/XsCc8+C1OmhKRx1VXQvj38v/+npV2l1ktypbz2ZvYPM5tnZnPM7KexvIWZTTGzBfGzecY9Q81soZnNN7PeGeXdzWxWPDfcEm6FVm8o2aLjjgsLLc2cGeaeuu8+KCkJM9wuWpR2dCKJSPLNYh3wc3fvDPQEBptZF2AIMNXdS4Cp8Zh4rj+wP2Gt7jvNrF581ghgEGGp1ZJ4PhHqDSVb7YADwtoZb74JAwbAqFEhaZx9tgb3Sa2TWLJw9+XuPiPurwLmAe2AvsDoeNlooF/c7ws86O5r3H0xYQnVHmbWFmjq7tM8tDyPybhHJH177AF33QVvvw1XXgmPPQYHHxzmopo+Pe3oRKpEtbRZmFkH4CDgJaCNuy+HkFCA1vGydsCSjNuWxrJ2cT+7PNf3DDKzMjMrW7lyZZX+DCJ57b47/Pa3sGQJ/M//wMsvwyGHhGlEnnoK1MtOarDEk4WZ7Qz8Fbjc3T/b0qU5ynwL5ZsXuo9y91J3L23VqtW2B7vxOZW+V4TmzWHIEFi8OAzse+st6N07vG2MHQtr16Ydocg2SzRZmFkDQqIY6+6PxOIPYtUS8bN8PoWlQPuM24uBZbG8OEd5MjGr66xUlSZN4Gc/g4ULQzXVmjVw7rmhXeMPf4BPP007QpGtlmRvKAPuBua5++8zTk0EBsb9gcCEjPL+ZtbQzDoSGrKnx6qqVWbWMz5zQMY9IoWvYUM4/3yYPTu0ZxQXwxVXhG63l18ekolIgUvyzeJw4IfAMWb2WtxOBIYBvcxsAdArHuPuc4DxwFxgMjDY3dfHZ10E/JnQ6L0ImJRg3Oo6K8koKoKTT4bnn4dXXoFTToE77oB99gn7Tz8NGzakHaVITlZb6+dLS0u9rKxsm+87+69nM2P5DOZfMj+BqESyLF8Of/pTSBoffRRGhl92Weh+26ZN2tFJHWRmr7h7aXa5RnCLpKltW7jhhtCDatw42G230M7Rrl1oFB87Vsu+SkFQssihtr5tSQFr1Aj694cXXwxtG1ddFdbXOPfc0LZx5ZWh6kp/NyUlShZZ1BtKUrf//vDrX4eG78mT4bDDwkp+paWhJ9WNN4YBgCLVSMlCpFAVFYWqqEcfhfffD91v99wzTJXesSMceWRo7/jPf9KOVOoAJYsc1BtKCk6LFqH77dSp4a3ippvggw/gootCO8cpp4Q2j6++SjtSqaWULLJoIkEpeHvuCddeC2+8ESYsvOwyeO01+MEPQg+qH/4QJkxQ4pAqpWQhUlOZQbduYdnXd94J4zTOOAOeeAL69YNWrUIX3EcegS++SDtaqeGULHJQbyipcYqKwtKvd98d2jeeeiokiqefhu99LySO738fxo/XOuJSKUoWWdQbSmq8Bg2gV6+wvsby5aGdY+BAeO45OOssaN06JJBx42DVqrSjlRpCyUKkNqtfH445Bu68E957D/75TzjvvLCeeHkbx2mnwZgx8OGHaUcrBUzJQqSuqFcvdLe97TZYujS8afzkJ2GBpoEDw2jyXr3CmI758zUAUDahZJGDus5KrVdUBN/5Dtx+e5hqpKwMfv7zkER++lPYb7+wAuAFF8DEiWogFyWLbOo6K3VOURF07w7DhsG8eWHk+MiRYcT4uHHQty+0bAmnnx4GBr7zTtoRSwrqpx2AiBSYvfYK26BBYRLD554Lo8gnTAifEKZVP/54+O53Q9VWy5bpxiyJ05tFFsPY4FpTQASAHXaA444LU6gvWQJz58If/wh77w333LOxW263bmE0+WOPwerVaUctCUhypbx7zGyFmc3OKGthZlPMbEH8bJ5xbqiZLTSz+WbWO6O8u5nNiueGW8L1REVWpHEWIrmYQefOoU3j73+Hjz+GF14IU4+0ahWmUz/1VNhlFzjkkDDV+oMPwrLEVkGWapTkm8W9QJ+ssiHAVHcvAabGY8ysC9Af2D/ec6eZ1Yv3jAAGEZZZLcnxzCpVZEV6sxDZGjvsEGbEvfZamDIFVq4MgwGvvjqcGzkyDAxs1w46dQrTrY8cGaZg14qANU5ibRbu/pyZdcgq7gscHfdHA88CV8fyB919DbDYzBYCPczsbaCpu08DMLMxQD8SXFa1yIpY/81qriKy1Ro2DF1ve/UKx2vXwuuvhzaP558Po8nHjg3nmjWDnj3DG8i3vx32d901tdAlv+pu4G7j7ssB3H25mbWO5e2Af2dctzSWrY372eU5mdkgwlsIe+yxR6UCrGf19GYhUhUaNAi9rLp3D1VS7rBoUai6euGFMDDwqac2vmXss09IGj17wqGHhnU9GjRI92eQbxRKb6hc7RC+hfKc3H0UMArCGtyVCUTVUCIJMQsN43vvHQYBQmgMLysLiWPatLDY05gx4VzjxtCjBxx+eNgOOyy0h0gqqjtZfGBmbeNbRVtgRSxfCrTPuK4YWBbLi3OUJ0bJQqQa7bQTHHVU2CC8fSxeDC+9FLbnnw/jP9avD8mmpCT0vDr4YDjiiLC/005p/gR1RnUni4nAQGBY/JyQUf6Amf0e2J3QkD3d3deb2Soz6wm8BAwAbksywCIrYv0GtVmIpMIsNIZ36hQaxyG8ffz732F98hkzQhIZPz6cKyoKPbS6dw+DCLt3hwMPVAJJQGLJwszGERqzW5rZUuA6QpIYb2bnAe8CZwK4+xwzGw/MBdYBg92/aWW+iNCzqhGhYTuxxm3Qm4VIwdlppzD9+rHHbixbsSIkkBkzQjXWk09urL4qTzgHHAAHHRQSyMEHh0kTNUNDpSXZG+rsCk4dm6vQ3W8Gbs5RXgZ0rcLQtqhekRq4RQpe69ZhTMepp4Zj9zCeo6wMZs6EWbPC59/+tnFCxBYtoEuX8Cay337wrW9B165hWVolkbwKpYG7YOjNQqQGMgvjOdq1C3NZlfvss7Dk7Kuvhnmv5swJU5ZkTsfevHlodC8pCcmjS5ewdewYpngXQMliM0oWIrVI06Zh7qojj9y0fOXKMDhw9uwwhcmiRaEx/YEHNl5Tv36YI6s8kZRv++wDxcVhyvc6RMkiiwblidQBrVqFSRC/+91Nyz/7LLyBzJ0LCxaEdT0WLYJ//GPTadobNgztIuVdgffaK7yJlJRAhw61cnyIkkUWvVmI1GFNm4ZR5Yccsml5eZvIggXw5pthGvfy7emn4csvN15bVATt24ek0anTpomkpCSMXq+BlCyyaAS3iGwms03k6KM3Pece1jpfvDgkkrfegrffDseTJsH77296fZMmG5PHHnuErX37ULVVXBwa3AuwikvJIoveLERkm5jB7ruH7fDDNz//xRchcSxYEN5EliwJCWX2bHjiiU3fSiAkirZtNyaP4uJNk0lxcThfzVVdShZZiixMxOvuWjVPRLZf48Zhnqv999/8nDv85z9hOdtc2+zZ4e0ke40Qs/AGkplAMrdDD63yZKJkkaU8Waz39dQ3/ecRkQSZhdl2d901jDzPxT00vGcmkSVLNu6/+SY88wx8+unGe1avVrJIWnmyUFWUiBQEszCB4i675H47KbdqFbz3XmiIb9y4ysNQsshSryg0LClZiEiN0qRJGJm+336JPF5rcGfRm4WIyOaULLIoWYiIbE7JIss3DdyaplxE5BtKFlkye0OJiEigZJGlcYPQi+DLtV/muVJEpO6oMcnCzPqY2XwzW2hmQ5L6nl0ahjV+P13zaZ4rRUTqjhqRLMysHnAHcALQBTjbzLok8V277BiTxVdKFiIi5WrKOIsewEJ3fwvAzB4E+hKWYa1S7Zq0A6DP2D7s3mR3DKPffv349bG/ruqvEhGpMWpKsmgHLMk4XgocUsG126Vr664MO3YYM96fgbvj+DcJRESkrqopySLXjH6+2UVmg4BBAHvssUflvsiMq4+4ulL3iojUVjWizYLwJtE+47gYWJZ9kbuPcvdSdy9t1apVtQUnIlLb1ZRk8TJQYmYdzWwHoD8wMeWYRETqjBpRDeXu68zsEuBJoB5wj7vPSTksEZE6o0YkCwB3fwJ4Iu04RETqoppSDSUiIilSshARkbyULEREJC8lCxERycvcNxvbViuY2UrgnUre3hL4sArDqWqKb/sUenxQ+DEqvu1TyPHt6e6bDVSrtclie5hZmbuXph1HRRTf9in0+KDwY1R826fQ48tF1VAiIpKXkoWIiOSlZJHbqLQDyEPxbZ9Cjw8KP0bFt30KPb7NqM1CRETy0puFiIjkpWQhIiJ5KVlkMLM+ZjbfzBaa2ZCEv+seM1thZrMzylqY2RQzWxA/m2ecGxrjmm9mvTPKu5vZrHhuuJlZLG9oZg/F8pfMrMM2xtfezP5hZvPMbI6Z/bSQYjSzHc1supnNjPHdUEjxZTy7npm9amaPF2h8b8dnv2ZmZYUWo5k1M7OHzeyN+Hfx0EKJz8z2jf/dyrfPzOzyQomvyrm7ttBuUw9YBHQCdgBmAl0S/L4jgYOB2RllvwWGxP0hwG/ifpcYT0OgY4yzXjw3HTiUsJrgJOCEWH4x8Ke43x94aBvjawscHPebAG/GOAoixvisneN+A+AloGehxJcR5xXAA8DjhfZnHO97G2iZVVYwMQKjgfPj/g5As0KKLyPOesD7wJ6FGF9VbKl8aSFu8Q/qyYzjocDQhL+zA5smi/lA27jfFpifKxbCuh6HxmveyCg/GxiZeU3cr08YLWrbEesEoFchxgg0BmYQ1mUvmPgIKzpOBY5hY7IomPjifW+zebIoiBiBpsDi7OsLJb6smI4HXijU+KpiUzXURu2AJRnHS2NZdWrj7ssB4mfrPLG1i/vZ5Zvc4+7rgE+BXSsTVHz1PYjw23vBxBireF4DVgBT3L2g4gP+CFwFbMgoK6T4IKxl/5SZvWJhDftCirETsBL4S6zK+7OZ7VRA8WXqD4yL+4UY33ZTstjIcpQVSr/iimLbUsxV8vOY2c7AX4HL3f2zLV1awfclFqO7r3f3boTf4HuYWddCic/MTgZWuPsrW3P9Fr4r6T/jw939YOAEYLCZHbmFa6s7xvqEqtoR7n4QsJpQrVMo8YUHhKWeTwX+L9+lFXxX4v8fVwUli42WAu0zjouBZdUcwwdm1hYgfq7IE9vSuJ9dvsk9ZlYf2AX4z7YEY2YNCIlirLs/UogxArj7J8CzQJ8Ciu9w4FQzext4EDjGzO4voPgAcPdl8XMF8CjQo4BiXAosjW+MAA8TkkehxFfuBGCGu38QjwstviqhZLHRy0CJmXWMvyn0ByZWcwwTgYFxfyChnaC8vH/sGdERKAGmx1fcVWbWM/aeGJB1T/mzzgCe8VjxuTXi8+4G5rn77wstRjNrZWbN4n4j4DjgjUKJz92Hunuxu3cg/F16xt3PLZT4AMxsJzNrUr5PqHefXSgxuvv7wBIz2zcWHQvMLZT4MpzNxiqo7GcWQnxVI42GkkLdgBMJvX4WAdcm/F3jgOXAWsJvD+cR6iKnAgviZ4uM66+Ncc0n9pSI5aWE/8EXAbezcVT+joTX4oWEnhadtjG+Iwivu68Dr8XtxEKJETgAeDXGNxv4VSwviPiyYj2ajQ3cBRMfoU1gZtzmlP+dL7AYuwFl8c/5b0DzAouvMfARsEtGWcHEV5WbpvsQEZG8VA0lIiJ5KVmIiEheShYiIpKXkoWIiOSlZCEiInkpWUitYmafx88OZvaDKn72NVnHL1bl86uamf3IzG5POw6pHZQspLbqAGxTsjCzenku2SRZuPth2xhTjbIV/z2kDlGykNpqGPCduM7Az+Kkg7eY2ctm9rqZXQBgZkdbWLfjAWBWLPtbnFhvTvnkemY2DGgUnzc2lpW/xVh89uy4JsFZGc9+1jauxzA2jtDdRLzmNxbW53jTzL4Tyzd5MzCzx83s6PLvjve8YmZPm1mP+Jy3zOzUjMe3N7PJFtZPuC7jWefG73vNzEaWJ4b43BvN7CXCjKgiQVqjAbVpS2IDPo+fRxNHTcfjQcAv435DwqjgjvG61UDHjGtbxM9GhFG1u2Y+O8d3fQ+YQljToA3wLmHa6aMJs4QWE34xmwYckSPmZ4Hfxf0Tgafj/o+A2zOuexw4Ou47G9c8eBR4irCux4HAaxn3LyeMKC7/WUqBzsBjQIN43Z3AgIznfj/tP0dthbfV3+bsIlIzHQ8cYGZnxONdCHPzfE2Yn2dxxrWXmdlpcb99vO6jLTz7CGCcu68nTCL3T+DbwGfx2UsBLEyn3gF4PsczyidqfCVek8/XwOS4PwtY4+5rzWxW1v1T3P2j+P2PxFjXAd2Bl+OLTiM2Tna3njB5pMgmlCykrjDgUnd/cpPCUK2zOuv4OMKCM1+Y2bOE+XnyPbsiazL211Px/3Nrclyzjk2rijPjWOvu5XP1bCi/3903WJidtFz2fD7lU2KPdvehOeL4KiY9kU2ozUJqq1WE5WDLPQlcZGHadcxsnzjTarZdgI9jotiPsFRrubXl92d5Djgrtou0IiyZO70Kfoa3gW5mVmRm7QnTh2+rXhbWhG4E9ANeIExud4aZtYZv1tzeswrilVpMbxZSW70OrDOzmcC9wP8SqmdmxEbmlYR/PLNNBi40s9cJM4P+O+PcKOB1M5vh7udklD9KaAyeSfjN/Sp3fz8mm+3xAmFZ0VmE9oYZlXjG88B9wN7AA+5eBmBmvySskFdEmPl4MPDOdsYrtZhmnRURkbxUDSUiInkpWYiISF5KFiIikpeShYiI5KVkISIieSlZiIhIXkoWIiKS1/8Hq8fwtpQw1z4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Визуализация изменения функционала ошибки\n",
    "plt.plot(range(len(errors_gs)), errors_gs, color='g')\n",
    "plt.plot(range(len(errors_sgs)), errors_sgs, color='r')\n",
    "plt.title('MSE')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Количество итераций по градиентному спуску на 2 порядка меньше (986 и 75746), чем по стохастическому градиентному спуску для обеспечения той же разницы весов (1e-8). Соответственно, сходимость стохастического градиентного спуска хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Модифицировать решение первого задания путем добавления 𝐿2 -регуляризации (в функцию, считающую MSE, нужно добавить норму вектора весов) и сравнить результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(x, W) + (lambda_/2) * np.sum(W**2) # Ridge - L2 регуляризация\n",
    "\n",
    "df/dw1 = d(w1**2 + w2**2 + w3**2) / dw1 = 2*w1 + 0 + 0 = 2*w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(data, predictors, alpha, models_to_plot={}):\n",
    "    \n",
    "    ridgereg = Ridge(alpha=alpha,normalize=True)\n",
    "    ridgereg.fit(data[predictors],data['y'])\n",
    "    y_pred = ridgereg.predict(data[predictors])\n",
    "    \n",
    "    # \n",
    "    if alpha in models_to_plot:\n",
    "        plt.subplot(models_to_plot[alpha])\n",
    "        plt.tight_layout()\n",
    "        plt.plot(data['x'],y_pred)\n",
    "        plt.plot(data['x'],data['y'],'.')\n",
    "        plt.title('Plot for alpha: %.3g'%alpha)\n",
    "    \n",
    "    # формат\n",
    "    rss = sum((y_pred-data['y'])**2)\n",
    "    ret = [rss]\n",
    "    ret.extend([ridgereg.intercept_])\n",
    "    ret.extend(ridgereg.coef_)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37879447, -0.61837549],\n",
       "       [-0.65293115, -1.06706712],\n",
       "       [-1.06581629, -0.34682333],\n",
       "       ...,\n",
       "       [ 1.19451016,  1.00147133],\n",
       "       [ 0.1256231 ,  0.35261274],\n",
       "       [-0.05674652,  0.41214611]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, target, coef = datasets.make_regression(n_samples=1000, n_features = 2, n_informative = 2, n_targets = 1, \n",
    "                                              noise = 5, coef = True, random_state = 2)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8a34474afa25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0merrors_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mridge_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0miter_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1368bbfcae8c>\u001b[0m in \u001b[0;36mridge_regression\u001b[0;34m(data, predictors, alpha, models_to_plot)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mridgereg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mridgereg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mridgereg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "X = data.copy()\n",
    "Y = target.copy()\n",
    "\n",
    "# начальный вектор весов\n",
    "w = np.zeros(2)\n",
    "\n",
    "# список векторов весов после каждой итерации\n",
    "w_list = [w.copy()]\n",
    "\n",
    "# список значений ошибок после каждой итерации\n",
    "errors_gs = []\n",
    "\n",
    "# шаг градиентного спуска\n",
    "eta = 0.01\n",
    "\n",
    "# максимальное число итераций\n",
    "max_iter = 1e4\n",
    "\n",
    "# критерий сходимости (разница весов, при которой алгоритм останавливается)\n",
    "min_weight_dist = 1e-8\n",
    "\n",
    "# начальная разница весов большим числом\n",
    "weight_dist = np.inf\n",
    "\n",
    "# счетчик итераций\n",
    "iter_num = 0\n",
    "\n",
    "# ход градиентного спуска\n",
    "while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "    new_w = w - 2 * eta * np.dot(X.T, (np.dot(X, w) - Y)) / Y.shape[0]\n",
    "    weight_dist = np.linalg.norm(new_w - w, ord=2)\n",
    "    \n",
    "    w_list.append(new_w.copy())\n",
    "    errors_gs.append(ridge_regression(X, new_w, Y))\n",
    "    \n",
    "    iter_num += 1\n",
    "    w = new_w\n",
    "    \n",
    "w_list = np.array(w_list)\n",
    "\n",
    "print(f'В результате выполнения градиентного спуска функционал ошибки = {round(errors_gs[-1], 4)}')\n",
    "print(f'Количество выполненных итераций = {iter_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-201ac536276c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0merrors_sgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mridge_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0miter_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1368bbfcae8c>\u001b[0m in \u001b[0;36mridge_regression\u001b[0;34m(data, predictors, alpha, models_to_plot)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mridgereg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mridgereg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mridgereg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "data = data.copy()\n",
    "target = target.copy()\n",
    "# начальный вектор весов\n",
    "w = np.zeros(2)\n",
    "\n",
    "# список векторов весов после каждой итерации\n",
    "w_list = [w.copy()]\n",
    "\n",
    "# список значений ошибок после каждой итерации\n",
    "errors_sgs = []\n",
    "\n",
    "# шаг градиентного спуска\n",
    "eta = 0.01\n",
    "\n",
    "# максимальное число итераций\n",
    "max_iter = 1e5\n",
    "\n",
    "# критерий сходимости (разница весов, при которой алгоритм останавливается)\n",
    "min_weight_dist = 1e-8\n",
    "\n",
    "# начальная разница весов большим числом\n",
    "weight_dist = np.inf\n",
    "\n",
    "# счетчик итераций\n",
    "iter_num = 0\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# ход градиентного спуска\n",
    "while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "    \n",
    "    # случайный индекс объекта выборки\n",
    "    train_ind = np.random.randint(data.shape[0])\n",
    "    \n",
    "    new_w = w - 2 * eta * np.dot(data[train_ind].T, (np.dot(data[train_ind], w) - target[train_ind])) / target.shape[0]\n",
    "\n",
    "    weight_dist = np.linalg.norm(new_w - w, ord=2)\n",
    "    \n",
    "    w_list.append(new_w.copy())\n",
    "    errors_sgs.append(ridge_regression(data, new_w, target))\n",
    "    \n",
    "    iter_num += 1\n",
    "    w = new_w\n",
    "    \n",
    "w_list = np.array(w_list)\n",
    "\n",
    "print(f'В результате выполнения стохастического градиентного спуска функционал ошибки = {round(errors_sgs[-1], 4)}')\n",
    "print(f'Количество выполненных итераций = {iter_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 [опция]. Модернизировать решение задания 2, заменив L2 регуляризацию на L1 регуляризацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(x, W) + (lambda_/2) * np.sum(np.abs(W)) # Lasso - L1 регуляризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regression(data, predictors, alpha, models_to_plot={}):\n",
    "    \n",
    "    lassoreg = Lasso(alpha=alpha,normalize=True, max_iter=1e5)\n",
    "    lassoreg.fit(data[predictors],data['y'])\n",
    "    y_pred = lassoreg.predict(data[predictors])\n",
    "    \n",
    "    \n",
    "    if alpha in models_to_plot:\n",
    "        plt.subplot(models_to_plot[alpha])\n",
    "        plt.tight_layout()\n",
    "        plt.plot(data['x'],y_pred)\n",
    "        plt.plot(data['x'],data['y'],'.')\n",
    "        plt.title('Plot for alpha: %.3g'%alpha)\n",
    "    \n",
    "    # формат\n",
    "    rss = sum((y_pred-data['y'])**2)\n",
    "    ret = [rss]\n",
    "    ret.extend([lassoreg.intercept_])\n",
    "    ret.extend(lassoreg.coef_)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37879447, -0.61837549],\n",
       "       [-0.65293115, -1.06706712],\n",
       "       [-1.06581629, -0.34682333],\n",
       "       ...,\n",
       "       [ 1.19451016,  1.00147133],\n",
       "       [ 0.1256231 ,  0.35261274],\n",
       "       [-0.05674652,  0.41214611]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, target, coef = datasets.make_regression(n_samples=1000, n_features = 2, n_informative = 2, n_targets = 1, \n",
    "                                              noise = 5, coef = True, random_state = 2)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-46c4f23b0594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0merrors_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0miter_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d8cf191f9d97>\u001b[0m in \u001b[0;36mlasso_regression\u001b[0;34m(data, predictors, alpha, models_to_plot)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlassoreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlassoreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlassoreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "X = data.copy()\n",
    "Y = target.copy()\n",
    "\n",
    "# начальный вектор весов\n",
    "w = np.zeros(2)\n",
    "\n",
    "# список векторов весов после каждой итерации\n",
    "w_list = [w.copy()]\n",
    "\n",
    "# список значений ошибок после каждой итерации\n",
    "errors_gs = []\n",
    "\n",
    "# шаг градиентного спуска\n",
    "eta = 0.01\n",
    "\n",
    "# максимальное число итераций\n",
    "max_iter = 1e4\n",
    "\n",
    "# критерий сходимости (разница весов, при которой алгоритм останавливается)\n",
    "min_weight_dist = 1e-8\n",
    "\n",
    "# начальная разница весов большим числом\n",
    "weight_dist = np.inf\n",
    "\n",
    "# счетчик итераций\n",
    "iter_num = 0\n",
    "\n",
    "# ход градиентного спуска\n",
    "while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "    new_w = w - 2 * eta * np.dot(X.T, (np.dot(X, w) - Y)) / Y.shape[0]\n",
    "    weight_dist = np.linalg.norm(new_w - w, ord=2)\n",
    "    \n",
    "    w_list.append(new_w.copy())\n",
    "    errors_gs.append(lasso_regression(X, new_w, Y))\n",
    "    \n",
    "    iter_num += 1\n",
    "    w = new_w\n",
    "    \n",
    "w_list = np.array(w_list)\n",
    "\n",
    "print(f'В результате выполнения градиентного спуска функционал ошибки = {round(errors_gs[-1], 4)}')\n",
    "print(f'Количество выполненных итераций = {iter_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d0741453b0dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mw_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0merrors_sgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0miter_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d8cf191f9d97>\u001b[0m in \u001b[0;36mlasso_regression\u001b[0;34m(data, predictors, alpha, models_to_plot)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlassoreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlassoreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlassoreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "data = data.copy()\n",
    "target = target.copy()\n",
    "# начальный вектор весов\n",
    "w = np.zeros(2)\n",
    "\n",
    "# список векторов весов после каждой итерации\n",
    "w_list = [w.copy()]\n",
    "\n",
    "# список значений ошибок после каждой итерации\n",
    "errors_sgs = []\n",
    "\n",
    "# шаг градиентного спуска\n",
    "eta = 0.01\n",
    "\n",
    "# максимальное число итераций\n",
    "max_iter = 1e5\n",
    "\n",
    "# критерий сходимости (разница весов, при которой алгоритм останавливается)\n",
    "min_weight_dist = 1e-8\n",
    "\n",
    "# начальная разница весов большим числом\n",
    "weight_dist = np.inf\n",
    "\n",
    "# счетчик итераций\n",
    "iter_num = 0\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "# ход градиентного спуска\n",
    "while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "    \n",
    "    # случайный индекс объекта выборки\n",
    "    train_ind = np.random.randint(data.shape[0])\n",
    "    \n",
    "    new_w = w - 2 * eta * np.dot(data[train_ind].T, (np.dot(data[train_ind], w) - target[train_ind])) / target.shape[0]\n",
    "\n",
    "    weight_dist = np.linalg.norm(new_w - w, ord=2)\n",
    "    \n",
    "    w_list.append(new_w.copy())\n",
    "    errors_sgs.append(lasso_regression(data, new_w, target))\n",
    "    \n",
    "    iter_num += 1\n",
    "    w = new_w\n",
    "    \n",
    "w_list = np.array(w_list)\n",
    "\n",
    "print(f'В результате выполнения стохастического градиентного спуска функционал ошибки = {round(errors_sgs[-1], 4)}')\n",
    "print(f'Количество выполненных итераций = {iter_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "\n",
    "1. Ключевое отличие\n",
    "\n",
    "**Ridge:** Включает в себя все (или ни одного) из функций модели. Таким образом, основным преимуществом регрессии Ridge является уменьшение коэффициента сжатия и снижение сложности модели.\n",
    "\n",
    "**Lasso:** Наряду с коэффициентами сжатия Lasso также выполняет выбор функций. Некоторые коэффициенты становятся равными нулю, что эквивалентно исключению конкретной функции из модели.\n",
    "Традиционно для выбора объектов и создания экономных моделей использовались такие методы, как пошаговая регрессия. Но с достижениями в области машинного обучения регрессия Ridge и Lasso предоставляет очень хорошие альтернативы, поскольку они дают гораздо лучшую производительность, требуют меньшего количества параметров настройки и могут быть в значительной степени автоматизированы.\n",
    "\n",
    "\n",
    "2. Типичные Случаи Использования\n",
    "\n",
    "**Ridge:** В основном используется для предотвращения переобучения, поскольку включает в себя все функции, он не очень полезен в случае чрезмерно высоких #функций, скажем, в миллионах, поскольку это создаст вычислительные проблемы.\n",
    "\n",
    "**Lasso:** Поскольку он предоставляет разреженные решения, это, как правило, модель выбора (или какой-либо вариант этой концепции) для моделирования случаев, когда #функций насчитывается миллионы или более. В таком случае получение разреженного решения имеет большое вычислительное преимущество, поскольку функции с нулевыми коэффициентами можно просто игнорировать.\n",
    "Нетрудно понять, почему методы пошагового выбора становятся практически очень громоздкими для реализации в случаях с высокой размерностью. Таким образом, Lasso дает значительное преимущество.\n",
    "\n",
    "\n",
    "3. Наличие сильно коррелированных признаков\n",
    "\n",
    "**Ridge:** Как правило, хорошо работает даже при наличии сильно коррелированных функций, поскольку он будет включать их все в модель, но коэффициенты будут распределены между ними в зависимости от корреляции.\n",
    "\n",
    "**Lasso:** Произвольно выбирает какой-либо один признак среди сильно коррелированных и сводит коэффициенты остальных к нулю. Кроме того, выбранная переменная изменяется случайным образом с изменением параметров модели. Как правило, это работает не так хорошо по сравнению с регрессией Ridge.\n",
    "Таким образом, даже небольшие значения альфа дают значительную разреженность (т. е. высокие #коэффициенты равны нулю).\n",
    "\n",
    "Наряду с Ridge и Lasso, **Elastic Net** является еще одним полезным методом, который сочетает в себе регуляризацию L1 и L2. Его можно использовать, чтобы сбалансировать плюсы и минусы регрессии Ridge и Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2016/01/ridge-lasso-regression-python-complete-tutorial/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
