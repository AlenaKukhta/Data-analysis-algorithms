{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание к Уроку 3. Логистическая регрессия. Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# from sklearn.linear_model import LinearRegression, SGDClassifier, SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1*. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y_true, y_pred):\n",
    "    k = 1e-5\n",
    "    y_pred = y_pred.copy()\n",
    "    y_pred = np.clip(y_pred, a_min=k, a_max=1-k)\n",
    "    err = - np.mean(y_true * np.log(y_pred) + (1.0 - y_true) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+00, 1.00e+00, 1.00e+00, 1.00e+00, 1.00e+00, 1.00e+00,\n",
       "        1.00e+00, 1.00e+00, 1.00e+00, 1.00e+00],\n",
       "       [1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00, 3.00e+00, 0.00e+00,\n",
       "        5.00e+00, 1.00e+01, 1.00e+00, 2.00e+00],\n",
       "       [5.00e+02, 7.00e+02, 7.50e+02, 6.00e+02, 1.45e+03, 8.00e+02,\n",
       "        1.50e+03, 2.00e+03, 4.50e+02, 1.00e+03],\n",
       "       [1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
       "        3.00e+00, 3.00e+00, 1.00e+00, 2.00e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450,\n",
    "               800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2, \n",
    "               1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_std_feat(x):\n",
    "    x[1:] = ((x[1:].T - x[1:].mean(axis=1)) / x[1:].std(axis=1)).T\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = calc_std_feat(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_std_feat(X):\n",
    "    X_tr = X[1:,].copy()\n",
    "    X_mean, X_std = X_tr.mean(axis=1), X_tr.std(axis=1)\n",
    "    X_mean, X_std = X_mean.reshape(X_tr.shape[0], 1), X_std.reshape(X_tr.shape[0], 1)\n",
    "    X_tr = (X_tr - X_mean)/X_std\n",
    "    X_tr = np.vstack((np.ones(X_tr.shape[1]), X_tr))\n",
    "    return X_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    rec = 1 / (1 + np.exp(-z))\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iteration, alpha=1e-4, k=1e-5):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    err = []\n",
    "    w = []\n",
    "    \n",
    "    for n_iter in range (1, iteration+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err_new = calc_logloss(y, y_pred)\n",
    "        W = W - alpha*(1/n * np.dot((y_pred - y), X.T))\n",
    "        #W -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "        err.append(err_new)\n",
    "        w.append(W)\n",
    "        \n",
    "        if n_iter > 2 and np.abs(err_new - err[-2]) < k:\n",
    "            print(n_iter, W, err_new)\n",
    "            break\n",
    "    err = np.array(err)\n",
    "    return err, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6236 [ 1.80385313 -5.00023322 -4.03203415 10.50060735] 0.20882355724960683\n",
      "6193 [ 0.22322901 -2.33314778 -0.81934289  3.73020567] 0.3379492576690167\n",
      "5495 [ 0.19641082 -0.94005846 -0.0076054   1.43621037] 0.49456917344192275\n",
      "8140 [ 0.45930427 -0.33157412  0.47217682  1.43686081] 0.6690360538916054\n"
     ]
    }
   ],
   "source": [
    "learning_model = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "for alpha1 in learning_model:\n",
    "    W = eval_model(X, y, iteration=1000000, alpha=alpha1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6236 [ 1.80385313 -5.00023322 -4.03203415 10.50060735] 0.20882355724960683\n",
      "6193 [ 0.22322901 -2.33314778 -0.81934289  3.73020567] 0.3379492576690167\n",
      "5495 [ 0.19641082 -0.94005846 -0.0076054   1.43621037] 0.49456917344192275\n",
      "8140 [ 0.45930427 -0.33157412  0.47217682  1.43686081] 0.6690360538916054\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.1, 0.01, 0.001, 0.0001]:\n",
    "    err_1, w_1 = eval_model(X=X, y=y, iteration = 1000000, alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(W, X):\n",
    "    y_pred = 1 /(1+ np.exp(-np.dot(W, X)))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24944723, 0.28765324, 0.70332289, 0.26811923, 0.80633815,\n",
       "       0.33380776, 0.95597403, 0.95132722, 0.24044325, 0.75149724])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pred_proba(w_1[-1], X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(W, X, threshold=0.5):\n",
    "    y_pred = calc_pred_proba(W, X)\n",
    "    y_pred = np.where(y_pred > threshold, 1, 0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = calc_pred(w_1[-1], X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y, y_pred):\n",
    "    conf_matrix = np.zeros(shape=(2,2))\n",
    "    # находим значение tp\n",
    "    conf_matrix[0,0] = np.sum(np.where(y==1,y==y_pred,False))\n",
    "    # находим значение tn\n",
    "    conf_matrix[1,1] = np.sum(np.where(y==0,y==y_pred,False))\n",
    "    # находим значение fn\n",
    "    conf_matrix[1,0] = np.sum(np.where(y==1,y!=y_pred,False))\n",
    "    # находим значение fp\n",
    "    conf_matrix[0,1] = np.sum(np.where(y==0,y!=y_pred,False))\n",
    "    \n",
    "    return conf_matrix.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 1],\n",
       "       [1, 4]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score (y, y_pred):\n",
    "    tp, tn, fn, fp = conf_matrix.flatten()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preсision_score (y, y_pred):            \n",
    "    tp, tn, fn, fp = conf_matrix.flatten()\n",
    "    preсision = tp /(tp + fp)\n",
    "    return preсision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preсision = preсision_score (y, y_pred)\n",
    "preсision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_score (y, y_pred):\n",
    "    tp, tn, fn, fp = conf_matrix.flatten()\n",
    "    recall = tp / (tp + fn)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y, y_pred)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score (y, y_pred):            \n",
    "    tp, tn, fn, fp = conf_matrix.flatten()\n",
    "    f1 = 2 * preсision * recall / (preсision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6153846153846154"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = f1_score (y, y_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель могла переобучиться из-за малого количества входных данных (непредставительная выборка) и ручного подбора порога разбиения на категории. Например, в решении 2 задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7*. Создайте функции eval_model_l1 и eval_model_l2 с применением L1 и L2 регуляризаций соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_l1(X, y, iterations, alpha=1e-4, lambda_ = 1e-7):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T) + lambda_ * np.sign(W))\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, W, err)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_l2(X, y, iterations, alpha=1e-4, lambda_=1e-8):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W -= alpha * (1/n * 2 * np.dot((y_pred - y), X.T) + lambda_ * W) \n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, W, err)\n",
    "    return W"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
